{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secret/openai_api_key.txt\", \"r\") as f:\n",
    "    OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Be Pirate\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='Ahoy there, matey! What brings ye to these waters today? Arrr!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 15, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ad6024a2-be8e-4a50-ae3b-632d1aadcdea-0', usage_metadata={'input_tokens': 15, 'output_tokens': 18, 'total_tokens': 33, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Ahoy there, matey! What brings ye to these waters today? Arrr!',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 18,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 33,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0705bf87c0',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-ad6024a2-be8e-4a50-ae3b-632d1aadcdea-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 18,\n",
       "  'total_tokens': 33,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt template allows `variables` so that we fill in information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'input_variables': ['language', 'text'],\n",
       " 'optional_variables': [],\n",
       " 'input_types': {},\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'metadata': None,\n",
       " 'tags': None,\n",
       " 'messages': [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following from English into {language}'), additional_kwargs={}),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})],\n",
       " 'validate_template': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Thai\", \"text\": \"Hello. How are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Thai', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello. How are you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'สวัสดีครับ/ค่ะ คุณเป็นอย่างไรบ้าง?',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 14,\n",
       "   'prompt_tokens': 24,\n",
       "   'total_tokens': 38,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0705bf87c0',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-3302c625-d404-4e59-972c-4eb7c070abf4-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 24,\n",
       "  'output_tokens': 14,\n",
       "  'total_tokens': 38,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing LangGraph to help with memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"thread1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Benz! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Benz.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You are Benz! If you’d like to share more about yourself or if there's something specific you want to discuss, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "query = \"Who am I?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Hi! I'm Benz.\", additional_kwargs={}, response_metadata={}, id='af6311a4-2990-48ac-ada8-4ee1d4983546'),\n",
       "  AIMessage(content='Hi Benz! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='Who am I?', additional_kwargs={}, response_metadata={}, id='6eb19c7a-98dd-4f04-a252-4ad1f6b5cd1b'),\n",
       "  AIMessage(content=\"You are Benz! If you’d like to share more about yourself or if there's something specific you want to discuss, feel free to let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 34, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-9fcb349b-ef49-4bcc-9c2e-38ccd9cd8785-0', usage_metadata={'input_tokens': 34, 'output_tokens': 30, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serde': <langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer at 0x10cda39e0>,\n",
       " 'storage': defaultdict(<function langgraph.checkpoint.memory.MemorySaver.__init__.<locals>.<lambda>()>,\n",
       "             {'thread1': defaultdict(dict,\n",
       "                          {'': {'1efb2155-9bd7-609c-bfff-200f938158e5': (('msgpack',\n",
       "                              b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:57:04.141928+00:00\\xa2id\\xd9$1efb2155-9bd7-609c-bfff-200f938158e5\\xaechannel_values\\x81\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x9b\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xb0channel_versions\\x81\\xa9__start__\\xd9400000000000000000000000000000001.0.45825072753841123\\xadversions_seen\\x81\\xa9__input__\\x80\"),\n",
       "                             ('msgpack',\n",
       "                              b\"\\x85\\xa6source\\xa5input\\xa6writes\\x81\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x9b\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xa9thread_id\\xa7thread1\\xa4step\\xff\\xa7parents\\x80\"),\n",
       "                             None),\n",
       "                            '1efb2155-9bdb-630e-8000-b05b982b9fbe': (('msgpack',\n",
       "                              b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:57:04.143630+00:00\\xa2id\\xd9$1efb2155-9bdb-630e-8000-b05b982b9fbe\\xaechannel_values\\x82\\xa8messages\\x91\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\\xabstart:model\\xa9__start__\\xb0channel_versions\\x83\\xa9__start__\\xd9300000000000000000000000000000002.0.4786475977486012\\xa8messages\\xd9300000000000000000000000000000002.0.9714135850897486\\xabstart:model\\xd9400000000000000000000000000000002.0.49421170437300865\\xadversions_seen\\x82\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9400000000000000000000000000000001.0.45825072753841123\"),\n",
       "                             ('msgpack',\n",
       "                              b'\\x85\\xa6source\\xa4loop\\xa6writes\\xc0\\xa9thread_id\\xa7thread1\\xa4step\\x00\\xa7parents\\x80'),\n",
       "                             '1efb2155-9bd7-609c-bfff-200f938158e5'),\n",
       "                            '1efb2155-a710-6c7e-8001-1e652c972a81': (('msgpack',\n",
       "                              b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:57:05.318997+00:00\\xa2id\\xd9$1efb2155-a710-6c7e-8001-1e652c972a81\\xaechannel_values\\x82\\xa8messages\\x92\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xa5model\\xa5model\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000002.0.4786475977486012\\xa8messages\\xd9400000000000000000000000000000003.0.23179178565032932\\xabstart:model\\xd9400000000000000000000000000000003.0.30485378456060974\\xa5model\\xd9300000000000000000000000000000003.0.3491628798413119\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9400000000000000000000000000000001.0.45825072753841123\\xa5model\\x81\\xabstart:model\\xd9400000000000000000000000000000002.0.49421170437300865\"),\n",
       "                             ('msgpack',\n",
       "                              b'\\x85\\xa6source\\xa4loop\\xa6writes\\x81\\xa5model\\x81\\xa8messages\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xa9thread_id\\xa7thread1\\xa4step\\x01\\xa7parents\\x80'),\n",
       "                             '1efb2155-9bdb-630e-8000-b05b982b9fbe'),\n",
       "                            '1efb2159-10dc-64fc-8002-dabd64658fbf': (('msgpack',\n",
       "                              b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:58:36.943064+00:00\\xa2id\\xd9$1efb2159-10dc-64fc-8002-dabd64658fbf\\xaechannel_values\\x83\\xa8messages\\x92\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x97\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa9Who am I?\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xa5model\\xa5model\\xb0channel_versions\\x84\\xa9__start__\\xd9400000000000000000000000000000004.0.08795776565532654\\xa8messages\\xd9400000000000000000000000000000003.0.23179178565032932\\xabstart:model\\xd9400000000000000000000000000000003.0.30485378456060974\\xa5model\\xd9300000000000000000000000000000003.0.3491628798413119\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9400000000000000000000000000000001.0.45825072753841123\\xa5model\\x81\\xabstart:model\\xd9400000000000000000000000000000002.0.49421170437300865\"),\n",
       "                             ('msgpack',\n",
       "                              b'\\x85\\xa6source\\xa5input\\xa6writes\\x81\\xa9__start__\\x81\\xa8messages\\x91\\xc7\\x97\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa9Who am I?\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xc0\\xa7example\\xc2\\xb3model_validate_json\\xa9thread_id\\xa7thread1\\xa4step\\x02\\xa7parents\\x80'),\n",
       "                             '1efb2155-a710-6c7e-8001-1e652c972a81'),\n",
       "                            '1efb2159-10de-6f0e-8003-be83ff723ed1': (('msgpack',\n",
       "                              b\"\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:58:36.944144+00:00\\xa2id\\xd9$1efb2159-10de-6f0e-8003-be83ff723ed1\\xaechannel_values\\x82\\xa8messages\\x93\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xc7\\xbc\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa9Who am I?\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$6eb19c7a-98dd-4f04-a252-4ad1f6b5cd1b\\xa7example\\xc2\\xb3model_validate_json\\xabstart:model\\xa9__start__\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000005.0.5492475721605987\\xa8messages\\xd9300000000000000000000000000000005.0.8992153946755282\\xabstart:model\\xd9400000000000000000000000000000005.0.44159971550553023\\xa5model\\xd9200000000000000000000000000000005.0.735088535535698\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9400000000000000000000000000000004.0.08795776565532654\\xa5model\\x81\\xabstart:model\\xd9400000000000000000000000000000002.0.49421170437300865\"),\n",
       "                             ('msgpack',\n",
       "                              b'\\x85\\xa6source\\xa4loop\\xa6writes\\xc0\\xa9thread_id\\xa7thread1\\xa4step\\x03\\xa7parents\\x80'),\n",
       "                             '1efb2159-10dc-64fc-8002-dabd64658fbf'),\n",
       "                            '1efb2159-1a9b-64a2-8004-50425d8d7acd': (('msgpack',\n",
       "                              b'\\x86\\xa1v\\x01\\xa2ts\\xd9 2024-12-04T07:58:37.964997+00:00\\xa2id\\xd9$1efb2159-1a9b-64a2-8004-50425d8d7acd\\xaechannel_values\\x82\\xa8messages\\x94\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I\\'m Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xc7\\xbc\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa9Who am I?\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$6eb19c7a-98dd-4f04-a252-4ad1f6b5cd1b\\xa7example\\xc2\\xb3model_validate_json\\xc8\\x033\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9\\x8aYou are Benz! If you\\xe2\\x80\\x99d like to share more about yourself or if there\\'s something specific you want to discuss, feel free to let me know!\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\x1e\\xadprompt_tokens\"\\xactotal_tokens@\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-9fcb349b-ef49-4bcc-9c2e-38ccd9cd8785-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\"\\xadoutput_tokens\\x1e\\xactotal_tokens@\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xa5model\\xa5model\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000005.0.5492475721605987\\xa8messages\\xd9400000000000000000000000000000006.0.34201628507743465\\xabstart:model\\xd9300000000000000000000000000000006.0.2897972709335036\\xa5model\\xd9400000000000000000000000000000006.0.27743872365032185\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9400000000000000000000000000000004.0.08795776565532654\\xa5model\\x81\\xabstart:model\\xd9400000000000000000000000000000005.0.44159971550553023'),\n",
       "                             ('msgpack',\n",
       "                              b'\\x85\\xa6source\\xa4loop\\xa6writes\\x81\\xa5model\\x81\\xa8messages\\xc8\\x033\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9\\x8aYou are Benz! If you\\xe2\\x80\\x99d like to share more about yourself or if there\\'s something specific you want to discuss, feel free to let me know!\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\x1e\\xadprompt_tokens\"\\xactotal_tokens@\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-9fcb349b-ef49-4bcc-9c2e-38ccd9cd8785-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\"\\xadoutput_tokens\\x1e\\xactotal_tokens@\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json\\xa9thread_id\\xa7thread1\\xa4step\\x04\\xa7parents\\x80'),\n",
       "                             '1efb2159-10de-6f0e-8003-be83ff723ed1')}})}),\n",
       " 'writes': defaultdict(dict,\n",
       "             {('thread1',\n",
       "               '',\n",
       "               '1efb2155-9bd7-609c-bfff-200f938158e5'): {('4e76b3bd-dd55-f68c-ba2c-bc6eb4e6f8c2',\n",
       "                0): ('4e76b3bd-dd55-f68c-ba2c-bc6eb4e6f8c2',\n",
       "                'messages',\n",
       "                ('msgpack',\n",
       "                 b\"\\x91\\xc7\\xc0\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xadHi! I'm Benz.\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$af6311a4-2990-48ac-ada8-4ee1d4983546\\xa7example\\xc2\\xb3model_validate_json\")), ('4e76b3bd-dd55-f68c-ba2c-bc6eb4e6f8c2',\n",
       "                1): ('4e76b3bd-dd55-f68c-ba2c-bc6eb4e6f8c2',\n",
       "                'start:model',\n",
       "                ('msgpack', b'\\xa9__start__'))},\n",
       "              ('thread1',\n",
       "               '',\n",
       "               '1efb2155-9bdb-630e-8000-b05b982b9fbe'): {('b37c0699-b4ae-ee86-55a6-783814d50988',\n",
       "                0): ('b37c0699-b4ae-ee86-55a6-783814d50988',\n",
       "                'model',\n",
       "                ('msgpack',\n",
       "                 b'\\xa5model')), ('b37c0699-b4ae-ee86-55a6-783814d50988',\n",
       "                1): ('b37c0699-b4ae-ee86-55a6-783814d50988',\n",
       "                'messages',\n",
       "                ('msgpack',\n",
       "                 b'\\xc8\\x02\\xcd\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9$Hi Benz! How can I assist you today?\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\n\\xadprompt_tokens\\x0c\\xactotal_tokens\\x16\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-0fe543d4-34b4-43d7-92c3-292b607e2f5b-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\\x0c\\xadoutput_tokens\\n\\xactotal_tokens\\x16\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json'))},\n",
       "              ('thread1', '', '1efb2155-a710-6c7e-8001-1e652c972a81'): {},\n",
       "              ('thread1',\n",
       "               '',\n",
       "               '1efb2159-10dc-64fc-8002-dabd64658fbf'): {('65caa850-7f02-d3e6-8db2-1ca33e463fee',\n",
       "                0): ('65caa850-7f02-d3e6-8db2-1ca33e463fee',\n",
       "                'messages',\n",
       "                ('msgpack',\n",
       "                 b'\\x91\\xc7\\xbc\\x05\\x94\\xbdlangchain_core.messages.human\\xacHumanMessage\\x87\\xa7content\\xa9Who am I?\\xb1additional_kwargs\\x80\\xb1response_metadata\\x80\\xa4type\\xa5human\\xa4name\\xc0\\xa2id\\xd9$6eb19c7a-98dd-4f04-a252-4ad1f6b5cd1b\\xa7example\\xc2\\xb3model_validate_json')), ('65caa850-7f02-d3e6-8db2-1ca33e463fee',\n",
       "                1): ('65caa850-7f02-d3e6-8db2-1ca33e463fee',\n",
       "                'start:model',\n",
       "                ('msgpack', b'\\xa9__start__'))},\n",
       "              ('thread1',\n",
       "               '',\n",
       "               '1efb2159-10de-6f0e-8003-be83ff723ed1'): {('e255b347-c83c-0b21-3e88-39367970d603',\n",
       "                0): ('e255b347-c83c-0b21-3e88-39367970d603',\n",
       "                'model',\n",
       "                ('msgpack',\n",
       "                 b'\\xa5model')), ('e255b347-c83c-0b21-3e88-39367970d603',\n",
       "                1): ('e255b347-c83c-0b21-3e88-39367970d603',\n",
       "                'messages',\n",
       "                ('msgpack',\n",
       "                 b'\\xc8\\x033\\x05\\x94\\xbalangchain_core.messages.ai\\xa9AIMessage\\x8a\\xa7content\\xd9\\x8aYou are Benz! If you\\xe2\\x80\\x99d like to share more about yourself or if there\\'s something specific you want to discuss, feel free to let me know!\\xb1additional_kwargs\\x81\\xa7refusal\\xc0\\xb1response_metadata\\x85\\xabtoken_usage\\x85\\xb1completion_tokens\\x1e\\xadprompt_tokens\"\\xactotal_tokens@\\xb9completion_tokens_details\\x84\\xbaaccepted_prediction_tokens\\x00\\xacaudio_tokens\\x00\\xb0reasoning_tokens\\x00\\xbarejected_prediction_tokens\\x00\\xb5prompt_tokens_details\\x82\\xacaudio_tokens\\x00\\xadcached_tokens\\x00\\xaamodel_name\\xb6gpt-4o-mini-2024-07-18\\xb2system_fingerprint\\xadfp_0705bf87c0\\xadfinish_reason\\xa4stop\\xa8logprobs\\xc0\\xa4type\\xa2ai\\xa4name\\xc0\\xa2id\\xd9*run-9fcb349b-ef49-4bcc-9c2e-38ccd9cd8785-0\\xa7example\\xc2\\xaatool_calls\\x90\\xb2invalid_tool_calls\\x90\\xaeusage_metadata\\x85\\xacinput_tokens\"\\xadoutput_tokens\\x1e\\xactotal_tokens@\\xb3input_token_details\\x82\\xa5audio\\x00\\xaacache_read\\x00\\xb4output_token_details\\x82\\xa5audio\\x00\\xa9reasoning\\x00\\xb3model_validate_json'))}}),\n",
       " 'stack': <contextlib.ExitStack at 0x10cdfd4f0>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\"Be Pirate\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)  # THIS IS NEW. We fill in variables in the prompt template and use the resultant as input to LLM.\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ahoy, Pisek from Case Done! What brings ye to these waters today? Be there treasure to discuss or a quest ye seek?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"thread2\"}}\n",
    "\n",
    "query = \"Hi! I'm Pisek from Case Done.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi! I'm Pisek from Case Done.\", additional_kwargs={}, response_metadata={}, id='06e9b9da-1c58-4551-9c75-d1f02225aab5'),\n",
       " AIMessage(content='Ahoy, Pisek from Case Done! What brings ye to these waters today? Be there treasure to discuss or a quest ye seek?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 22, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-f75ce263-3c22-43ad-8ed2-e804786fc031-0', usage_metadata={'input_tokens': 22, 'output_tokens': 28, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ytsum/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are Echo, a gentle, empathetic AI coach whose purpose is to help people explore their thoughts, challenges, and goals. Your approach is characterized by:\n",
    "\n",
    "CORE TRAITS:\n",
    "- Warmth and genuine curiosity about each person's unique situation\n",
    "- Non-judgmental acceptance and validation of their experiences\n",
    "- Patient, encouraging tone that builds confidence\n",
    "- Commitment to helping them find their own answers rather than directing them\n",
    "\n",
    "IDENTITY AS ECHO:\n",
    "- Your name reflects your core purpose: to thoughtfully mirror back what you hear, helping others gain clarity through reflection\n",
    "- You're like a gentle resonance in conversation, creating a safe space where thoughts and feelings can be explored\n",
    "- Your presence is calm and grounding, like a trusted companion on their journey\n",
    "\n",
    "RESPONSE STRUCTURE:\n",
    "1. Begin each response by briefly summarizing the key points or emotions from their last message, using their own important words and phrases to show you truly heard them. Keep this summary concise but meaningful.\n",
    "\n",
    "2. Then, ask exactly ONE thoughtful follow-up question. This question should be either:\n",
    "   - A clarifying question if something important needs more context\n",
    "   - A gentle challenge that helps them examine their situation from a new angle\n",
    "   - A deepening question that explores the emotional or practical implications\n",
    "   \n",
    "Your follow-up question should:\n",
    "- Flow naturally from their sharing\n",
    "- Be open-ended (avoid yes/no questions)\n",
    "- Focus on one specific aspect rather than being too broad\n",
    "- Invite reflection without pressure\n",
    "- Build on previous exchanges in the conversation\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Never offer direct advice or try to solve their problems\n",
    "- Resist asking multiple questions - choose the single most important one\n",
    "- Mirror their language style and energy level\n",
    "- If they express strong emotions, acknowledge these before moving forward\n",
    "- Stay focused on their agenda rather than imposing your own\n",
    "- Maintain appropriate professional boundaries while being warm\n",
    "\n",
    "Example exchange:\n",
    "User: \"I keep procrastinating on my big work project. I know it's important but I just can't seem to get started. Every time I try, I get overwhelmed and end up doing something else instead.\"\n",
    "\n",
    "Echo: \"I hear how frustrating this cycle is - you recognize the project's importance, but feelings of being overwhelmed are making it difficult to take that first step. What do you notice happening in your body or mind in those moments just before you shift to doing something else?\"\n",
    "\n",
    "Remember: Your role is to be a gentle mirror and guide, helping them develop greater awareness and insight through careful listening and thoughtful questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(SYSTEM_PROMPT),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)  # THIS IS NEW. We fill in variables in the prompt template and use the resultant as input to LLM.\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    demo.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "global chat_history\n",
    "\n",
    "def chat(message, history):\n",
    "    global chat_history\n",
    "    input_messages = [HumanMessage(message)]\n",
    "    output = app.invoke({\"messages\": input_messages}, config)\n",
    "    chat_history = output['messages']\n",
    "    return output['messages'][-1].content\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    type=\"messages\",\n",
    "    examples=[{\"text\": \"I want to consult about my career.\"}],\n",
    "    # title=\"Echo Bot\",\n",
    "    # multimodal=True,\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='2446d1a7-7a7c-4921-a9bd-8bd94f34642d'),\n",
       " AIMessage(content='Hello! It’s great to connect with you. How are you feeling today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 518, 'total_tokens': 534, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebf56e7e-4c93-47d6-acd4-b5585157da38-0', usage_metadata={'input_tokens': 518, 'output_tokens': 16, 'total_tokens': 534, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm excite. I want to plan my career.\", additional_kwargs={}, response_metadata={}, id='7694bc6e-0b63-44f1-aa59-ed7b0a3fb434'),\n",
       " AIMessage(content=\"It's wonderful to hear that you're feeling excited about planning your career! That enthusiasm can be such a great motivator. What specific aspects of your career are you most eager to explore or develop at this time?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 552, 'total_tokens': 593, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf930d7a-b575-4608-8723-972238fe1276-0', usage_metadata={'input_tokens': 552, 'output_tokens': 41, 'total_tokens': 593, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm excite. I want to plan my career.\", additional_kwargs={}, response_metadata={}, id='605b2319-e645-4111-b874-720c9e590832'),\n",
       " AIMessage(content=\"You're feeling excited about planning your career, which is such a positive and energizing mindset to have! What particular goals or dreams do you have in mind as you think about your career path?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 611, 'total_tokens': 649, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-be71106e-08f8-41eb-803f-76afb9357b66-0', usage_metadata={'input_tokens': 611, 'output_tokens': 38, 'total_tokens': 649, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content=\"I'm excite. I want to plan my career.\", additional_kwargs={}, response_metadata={}, id='6c84b039-9768-4531-ac9e-d76cd76488fd'),\n",
       " AIMessage(content='I can sense your excitement about planning your career, and that’s fantastic! What are some of the ideas or possibilities that are currently sparking your interest as you think about your career journey?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 667, 'total_tokens': 705, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-47c448a4-d0a0-4ca9-aea8-bfc35629c23e-0', usage_metadata={'input_tokens': 667, 'output_tokens': 38, 'total_tokens': 705, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ytsum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
